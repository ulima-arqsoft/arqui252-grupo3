> [9. Metodolog√≠a de Dise√±o de Arquitectura - Aplicaci√≥n de ADD](../../9.md) ‚Ä∫ [9.4. Iteraci√≥n 3: Refinar estructuras para abordar el atributo de calidad m√°s importante](../9.4.md) ‚Ä∫ [9.4.4. Elementos instanciados](9.4.4.md)

# 9.4.4. Elementos instanciados

## Elementos Arquitect√≥nicos Instanciados para Tiempo Real y Disponibilidad

A partir de los conceptos de dise√±o definidos en la secci√≥n anterior, se instancian los siguientes elementos arquitect√≥nicos concretos en el sistema InnovaLogix Retail ERP:

---

### 1. Servidor WebSocket con Socket.IO

**Responsabilidad:** Gestionar conexiones persistentes bidireccionales con clientes frontend, emitir eventos de dominio en tiempo real, y mantener rooms para broadcasting selectivo.

**Componentes instanciados:**

#### 1.1. Socket Server Instance
- **Ubicaci√≥n:** Backend Node.js, archivo `server/socketServer.js`
- **Puerto:** 3001 (separado del API REST en puerto 3000)
- **Configuraci√≥n CORS:** Origen permitido desde Vercel y localhost
- **Transports habilitados:** WebSocket prioritario, polling como fallback
- **Capacidad:** Hasta 50 conexiones simult√°neas por instancia
- **Heartbeat:** Ping autom√°tico cada 25 segundos con timeout de 5 segundos

#### 1.2. Event Emitter Service
- **Ubicaci√≥n:** `server/services/eventEmitter.js`
- **Responsabilidad:** Centralizar emisi√≥n de eventos de dominio desde controllers
- **M√©todos p√∫blicos:**
  - `emitStockUpdate(productId, newStock, action)` - Emite cuando stock cambia
  - `emitLowStockAlert(productId, currentStock, minStock)` - Emite cuando stock bajo umbral
  - `emitSaleCompleted(saleId, total, items)` - Emite cuando venta se registra exitosamente
  - `emitProductCreated(product)` - Emite cuando producto nuevo se crea
  - `emitCustomerCreated(customer)` - Emite cuando cliente nuevo se registra
  - `emitPurchaseReceived(purchaseId, supplierId)` - Emite cuando se recepciona mercader√≠a

#### 1.3. Room Manager
- **Ubicaci√≥n:** `server/services/roomManager.js`
- **Responsabilidad:** Gestionar rooms de Socket.IO para segmentaci√≥n de notificaciones
- **Rooms definidos:**
  - `pos-users` - Cajeros con m√≥dulo POS abierto
  - `inventory-users` - Personal de almac√©n con m√≥dulo Inventario abierto
  - `purchases-users` - Encargados de compras
  - `reports-users` - Gerentes con m√≥dulo Reportes abierto
  - `admin-users` - Administradores con acceso completo
- **L√≥gica de uni√≥n:** Al conectar, cliente emite evento `join-room` con rol y m√≥dulo activo, servidor lo agrega a room correspondiente y confirma con evento `room-joined`

#### 1.4. Reconnection Handler (Cliente)
- **Ubicaci√≥n:** Frontend, `src/services/socketService.js`
- **Responsabilidad:** Manejar reconexiones autom√°ticas con backoff exponencial
- **Estrategia de retry:**
  - Intento 1: Inmediato al detectar desconexi√≥n
  - Intento 2: Espera 1 segundo
  - Intento 3: Espera 2 segundos
  - Intento 4: Espera 4 segundos
  - Intento 5: Espera 8 segundos
  - Intentos 6+: Espera 16 segundos (m√°ximo plateau)
  - Despu√©s de 10 intentos fallidos consecutivos: Mostrar modal sugiriendo refresh manual de p√°gina

#### 1.5. Event Buffer para Clientes Desconectados
- **Ubicaci√≥n:** `server/services/eventBuffer.js`
- **Responsabilidad:** Retener eventos no entregados durante desconexi√≥n temporal
- **Capacidad:** Hasta 100 eventos por cliente desconectado
- **Ventana de retenci√≥n:** 5 minutos desde desconexi√≥n
- **L√≥gica:** Al reconectar, cliente solicita eventos pendientes con timestamp de √∫ltima recepci√≥n, servidor env√≠a todos los eventos posteriores a ese timestamp que a√∫n est√©n en buffer

---

### 2. Sistema de Cach√© con node-cache

**Responsabilidad:** Almacenar en memoria datos frecuentemente consultados con pol√≠ticas de TTL diferenciadas e invalidaci√≥n sincronizada.

**Componentes instanciados:**

#### 2.1. Product Cache Instance
- **Ubicaci√≥n:** `server/cache/productCache.js`
- **Configuraci√≥n:**
  - TTL est√°ndar: 600 segundos (10 minutos)
  - Check period: 120 segundos (limpieza autom√°tica cada 2 minutos)
  - Max keys: 1000 entradas (aproximadamente 50MB de memoria)
  - Use clones: false (compartir referencias para mejor performance)
- **Keys principales:**
  - `all_products` - Lista completa de productos activos con stock
  - `product:{id}` - Detalle de producto individual por ID
  - `products_by_category:{categoryId}` - Productos filtrados por categor√≠a espec√≠fica
  - `low_stock_products` - Productos con stock actual bajo umbral m√≠nimo configurado
  - `top_selling_products` - Top 20 productos m√°s vendidos en √∫ltimos 30 d√≠as

#### 2.2. Category Cache Instance
- **Ubicaci√≥n:** `server/cache/categoryCache.js`
- **Configuraci√≥n:**
  - TTL est√°ndar: 1800 segundos (30 minutos, m√°s longevo por ser relativamente est√°tico)
  - Check period: 600 segundos
  - Max keys: 100 entradas
- **Keys principales:**
  - `all_categories` - Lista de todas las categor√≠as con conteo de productos
  - `category:{id}` - Detalle de categor√≠a individual con metadata

#### 2.3. Cache Invalidator Service
- **Ubicaci√≥n:** `server/services/cacheInvalidator.js`
- **Responsabilidad:** Invalidar entries relevantes del cache cuando ocurren escrituras en BD
- **M√©todos p√∫blicos:**
  - `invalidateProduct(productId)` - Invalida cache de producto espec√≠fico, lista completa y categor√≠a asociada
  - `invalidateAllProducts()` - Invalida todas las keys relacionadas con productos (usado en importaciones masivas)
  - `invalidateCategory(categoryId)` - Invalida cache de categor√≠a y todos los productos asociados
  - `invalidateLowStock()` - Invalida cache de productos bajo stock (llamado tras ajustes de inventario)
- **Invocaci√≥n:** Llamado autom√°ticamente desde controllers despu√©s de commits exitosos en PostgreSQL, garantizando consistencia eventual <100ms

#### 2.4. Cache Metrics Collector
- **Ubicaci√≥n:** `server/monitoring/cacheMetrics.js`
- **Responsabilidad:** Recolectar m√©tricas de efectividad del cache para optimizaci√≥n
- **M√©tricas registradas cada minuto:**
  - Total hits acumulados
  - Total misses acumulados
  - Hit rate porcentual actual: `hits / (hits + misses) * 100`
  - Keys actualmente en cache con conteo
  - Memoria aproximada utilizada en MB (estimado 50KB por key promedio)
  - Keys m√°s accedidas en √∫ltima ventana de 5 minutos
- **Exposici√≥n:** Endpoint GET /api/metrics/cache retorna JSON con m√©tricas actuales para consumo del dashboard de monitoreo

#### 2.5. Cache Warming Service
- **Ubicaci√≥n:** `server/services/cacheWarmer.js`
- **Responsabilidad:** Precarga proactiva de datos frecuentes al iniciar servidor
- **Estrategia de warming:**
  1. Al iniciar aplicaci√≥n, consultar ranking de productos m√°s buscados en √∫ltimos 30 d√≠as desde tabla analytics
  2. Cargar top 100 productos en cache con key `product:{id}`
  3. Cargar lista completa de categor√≠as en cache
  4. Cargar productos bajo stock m√≠nimo actual
  5. Logging de tiempo total de warming y cantidad de keys precargadas
- **Tiempo estimado:** 2-3 segundos para warming completo con 5000 productos en BD

---

### 3. Gestor de Transacciones PostgreSQL

**Responsabilidad:** Proveer interfaz simplificada para ejecutar operaciones dentro de transacciones ACID con retry autom√°tico ante deadlocks.

**Componentes instanciados:**

#### 3.1. Transaction Manager Service
- **Ubicaci√≥n:** `server/services/transactionManager.js`
- **Responsabilidad:** Ejecutar callbacks dentro de transacciones BEGIN-COMMIT con manejo de errores
- **M√©todo principal:**
  - `executeInTransaction(callback, options)` - Ejecuta callback dentro de transacci√≥n con retry logic
- **Par√°metros de options:**
  - `retries` (default 3): N√∫mero m√°ximo de reintentos ante deadlocks
  - `isolationLevel` (default 'READ COMMITTED'): Nivel de aislamiento PostgreSQL
  - `logErrors` (default true): Si debe logear errores en cada retry
- **Flujo de ejecuci√≥n:**
  1. Obtener client del pool de conexiones PostgreSQL
  2. Ejecutar `BEGIN` o `BEGIN TRANSACTION ISOLATION LEVEL {level}` seg√∫n configuraci√≥n
  3. Ejecutar callback pasando client como par√°metro
  4. Si callback retorna exitosamente: Ejecutar `COMMIT` y retornar resultado
  5. Si error con c√≥digo 40P01 (deadlock): Esperar backoff exponencial y reintentar
  6. Si otro tipo de error: Ejecutar `ROLLBACK` y propagar excepci√≥n original
  7. En bloque finally: Liberar client al pool con `client.release()`

#### 3.2. Isolation Level Manager
- **Ubicaci√≥n:** `server/services/isolationManager.js`
- **Responsabilidad:** Configurar nivel de aislamiento apropiado seg√∫n tipo de operaci√≥n
- **M√©todos p√∫blicos:**
  - `setReadCommitted(client)` - Configura `READ COMMITTED` (default, para operaciones est√°ndar)
  - `setSerializable(client)` - Configura `SERIALIZABLE` (para ajustes manuales cr√≠ticos de inventario)
  - `setRepeatableRead(client)` - Configura `REPEATABLE READ` (para reportes que requieren snapshot consistente)
- **Uso:** Invocado antes de BEGIN en Transaction Manager seg√∫n criticidad de operaci√≥n determinada por controller

#### 3.3. Deadlock Retry Handler
- **Ubicaci√≥n:** Integrado en Transaction Manager
- **Responsabilidad:** Implementar l√≥gica de backoff exponencial ante deadlocks de PostgreSQL
- **Estrategia detallada:**
  - Intento 1: Sin espera, ejecuci√≥n inmediata
  - Intento 2: Espera 100ms mediante `setTimeout` o `sleep`
  - Intento 3: Espera 200ms
  - Si falla despu√©s de 3 intentos: Retornar HTTP 409 Conflict con mensaje descriptivo indicando recurso bloqueado
- **Logging detallado:** Cada retry registra en logs con nivel WARNING incluyendo query SQL que caus√≥ deadlock, timestamp, intento n√∫mero, y stack trace original

#### 3.4. Pre-Transaction Validator
- **Ubicaci√≥n:** `server/validators/transactionValidator.js`
- **Responsabilidad:** Verificar precondiciones de negocio antes de iniciar transacci√≥n costosa
- **Validaciones implementadas:**
  - Antes de registrar venta: Verificar que todos los productos existan y tengan stock suficiente
  - Antes de ajustar inventario: Verificar que usuario tenga permisos de almacenero/admin
  - Antes de recepcionar compra: Verificar que orden de compra est√© en estado aprobado
  - Antes de canjear puntos: Verificar que cliente tenga saldo suficiente de puntos
- **Beneficio:** Reducir tasa de rollbacks evitando iniciar transacciones que inevitablemente fallar√°n, mejorando throughput del sistema

---

### 4. Service Worker y PWA Assets

**Responsabilidad:** Habilitar modo offline mediante cache de recursos est√°ticos y gesti√≥n de estrategias network/cache.

**Componentes instanciados:**

#### 4.1. Service Worker Registration
- **Ubicaci√≥n:** Frontend, archivo `public/service-worker.js`
- **Responsabilidad:** Registrar Service Worker al cargar aplicaci√≥n por primera vez
- **Estrategias de cache implementadas:**
  - **Cache-first:** Para assets est√°ticos inmutables (HTML, CSS, JS compilado, im√°genes, fuentes, logos)
  - **Network-first con timeout:** Para llamadas API GET con fallback a cache si network falla o timeout >5s
  - **Network-only:** Para operaciones de escritura POST, PUT, DELETE que siempre requieren servidor
  - **Stale-while-revalidate:** Para im√°genes de productos que pueden mostrarse de cache mientras se actualizan en background
- **Event listeners:**
  - `install`: Cachear assets cr√≠ticos en cache est√°tico nombrado `innovalogix-v1-static`
  - `activate`: Limpiar caches antiguos de versiones previas
  - `fetch`: Interceptar requests y aplicar estrategia seg√∫n patr√≥n de URL

#### 4.2. IndexedDB Schema
- **Ubicaci√≥n:** Frontend, `src/db/schema.js`
- **Base de datos:** `innovalogix_offline`
- **Versi√≥n actual:** 1
- **Object Stores definidos:**
  - `products` - Cat√°logo de productos con keys por ID num√©rico, √≠ndices en name y category
  - `customers` - Clientes frecuentes con keys por ID, √≠ndice en email y phone
  - `pending_sales` - Cola FIFO de ventas offline pendientes, keys autoincrementales, √≠ndice en timestamp
  - `pending_adjustments` - Cola de ajustes de inventario offline, estructura similar a pending_sales
  - `sync_metadata` - Metadata de √∫ltima sincronizaci√≥n: timestamps, versiones de schema, hash de √∫ltimo snapshot

#### 4.3. Offline Queue Manager
- **Ubicaci√≥n:** Frontend, `src/services/offlineQueue.js`
- **Responsabilidad:** Gestionar cola FIFO de operaciones pendientes durante modo offline
- **M√©todos p√∫blicos:**
  - `enqueue(operation)` - Agregar operaci√≥n a cola con timestamp ISO 8601 y hash SHA-256
  - `dequeueAll()` - Obtener todas las operaciones pendientes ordenadas por timestamp ascendente
  - `markSynced(operationId)` - Marcar operaci√≥n como sincronizada exitosamente y eliminar de cola
  - `getPendingCount()` - Obtener cantidad actual de operaciones pendientes (badge en UI)
  - `clearAll()` - Limpiar toda la cola (usado solo en casos de reset manual)
- **Persistencia:** Todas las operaciones se guardan en IndexedDB store `pending_sales` para sobrevivir refresh de p√°gina o cierre de navegador

#### 4.4. Sync Service
- **Ubicaci√≥n:** Frontend, `src/services/syncService.js`
- **Responsabilidad:** Sincronizar operaciones offline con servidor al detectar reconexi√≥n a internet
- **Flujo detallado de sincronizaci√≥n:**
  1. Detectar evento `online` del objeto `navigator` del navegador
  2. Mostrar toast notification "Sincronizando operaciones pendientes..."
  3. Obtener todas las operaciones pendientes de Offline Queue ordenadas cronol√≥gicamente
  4. Para cada operaci√≥n en orden FIFO:
     - Construir HTTP request al endpoint correspondiente con payload de operaci√≥n
     - Enviar request con timeout de 10 segundos
     - Si respuesta 2xx Success: Marcar operaci√≥n como sincronizada, incrementar contador de √©xitos
     - Si respuesta 409 Conflict: Mostrar modal con datos local vs servidor para resoluci√≥n manual, pausar sync
     - Si respuesta 4xx Client Error: Marcar operaci√≥n como fallida permanentemente, incrementar contador de errores, continuar con siguiente
     - Si respuesta 5xx Server Error: Detener sync completamente, programar retry autom√°tico en 30 segundos
     - Si timeout de network: Tratar como 5xx y programar retry
  5. Al completar cola exitosamente: Refrescar datos locales completos desde servidor con GET /api/sync/snapshot
  6. Actualizar timestamp de √∫ltima sincronizaci√≥n en sync_metadata
  7. Mostrar toast notification resumen: "Sincronizaci√≥n completa: X operaciones exitosas, Y errores"

#### 4.5. Conflict Resolver
- **Ubicaci√≥n:** Frontend, componente modal `src/components/ConflictResolverModal.jsx`
- **Responsabilidad:** Permitir resoluci√≥n manual de conflictos cuando datos locales difieren de servidor
- **Interfaz de usuario:**
  - Secci√≥n izquierda: Datos locales (offline) con timestamp de creaci√≥n
  - Secci√≥n derecha: Datos actuales en servidor con timestamp de √∫ltima modificaci√≥n
  - Bot√≥n "Usar datos locales" - Sobrescribe servidor con versi√≥n local
  - Bot√≥n "Usar datos del servidor" - Descarta cambios locales
  - Bot√≥n "Combinar manualmente" - Permite edici√≥n campo por campo antes de enviar
  - Bot√≥n "Cancelar" - Pausa sincronizaci√≥n y deja operaci√≥n en cola para resolver despu√©s
- **Persistencia de decisi√≥n:** Guarda resoluci√≥n en sync_metadata para no volver a preguntar si mismo conflicto reaparece

---

### 5. Sistema de Monitoreo y M√©tricas

**Responsabilidad:** Recolectar, almacenar, agregar y visualizar m√©tricas de performance y salud del sistema en tiempo real.

**Componentes instanciados:**

#### 5.1. Metrics Middleware (Express)
- **Ubicaci√≥n:** Backend, `server/middleware/metricsMiddleware.js`
- **Responsabilidad:** Interceptar todos los requests HTTP y registrar timestamps inicio/fin para calcular latencias
- **Implementaci√≥n t√©cnica:**
  - Al recibir request: Registrar `Date.now()` en propiedad `req.startTime`
  - Registrar event listener en evento `finish` de `res` para capturar momento de finalizaci√≥n
  - Al finalizar response: Calcular latencia como `Date.now() - req.startTime` en milisegundos
  - Emitir evento `metric:request` a Metrics Aggregator con objeto conteniendo: m√©todo HTTP, ruta, status code, latencia, timestamp
  - Si latencia excede 1000ms: Emitir tambi√©n evento `metric:slow-request` para alertas
- **Montaje:** Registrado como primer middleware en aplicaci√≥n Express antes de CORS y body parsers para medir latencia total

#### 5.2. Metrics Aggregator Service
- **Ubicaci√≥n:** Backend, `server/services/metricsAggregator.js`
- **Responsabilidad:** Agregar m√©tricas en ventanas deslizantes y calcular percentiles P50, P95, P99
- **Estructura de datos en memoria:**
  - Map de endpoints como keys: `GET /api/products`, `POST /api/sales`, etc.
  - Para cada endpoint: Array circular de √∫ltimas 1000 latencias medidas
  - Contadores: `totalRequests`, `successCount` (2xx), `clientErrorCount` (4xx), `serverErrorCount` (5xx)
  - Timestamp de √∫ltima actualizaci√≥n de m√©tricas
- **C√°lculo de percentiles (algoritmo):**
  1. Obtener array de latencias del endpoint
  2. Ordenar array num√©ricamente de menor a mayor con `sort()`
  3. P50 (mediana): Tomar valor en posici√≥n `Math.floor(array.length * 0.50)`
  4. P95: Tomar valor en posici√≥n `Math.floor(array.length * 0.95)`
  5. P99: Tomar valor en posici√≥n `Math.floor(array.length * 0.99)`
- **Actualizaci√≥n peri√≥dica:** Cada 60 segundos, recalcular todos los percentiles y persistir snapshot de m√©tricas en PostgreSQL

#### 5.3. Metrics Storage (PostgreSQL)
- **Tabla:** `performance_metrics`
- **Columnas detalladas:**
  - `id` UUID primary key generado con gen_random_uuid()
  - `timestamp` TIMESTAMPTZ not null con timezone UTC
  - `endpoint` VARCHAR(255) ruta del endpoint ejemplo `GET /api/products`
  - `p50_latency_ms` INTEGER latencia percentil 50 en milisegundos
  - `p95_latency_ms` INTEGER latencia percentil 95 en milisegundos
  - `p99_latency_ms` INTEGER latencia percentil 99 en milisegundos
  - `request_count` INTEGER total de requests en ventana de 1 minuto
  - `success_count` INTEGER requests con status 2xx
  - `error_count` INTEGER requests con status 5xx
  - `error_rate` DECIMAL(5,2) porcentaje de errores calculado como `error_count / request_count * 100`
- **√çndices:** √çndice compuesto en `(endpoint, timestamp DESC)` para queries de dashboard por rango de tiempo
- **Retenci√≥n:** Job scheduled ejecutado diariamente que elimina registros con `timestamp < NOW() - INTERVAL '30 days'` para mantener BD liviana

#### 5.4. Metrics Dashboard (Frontend)
- **Ubicaci√≥n:** Frontend, componente en ruta `/admin/metrics`
- **Responsabilidad:** Visualizar m√©tricas en tiempo real y tendencias hist√≥ricas con gr√°ficos interactivos
- **Componentes visuales implementados:**
  - **Gr√°fico de l√≠neas (Chart.js):** Latencias P95 de √∫ltimas 24 horas por endpoint con eje X temporal y eje Y en ms, l√≠neas de diferentes colores por endpoint
  - **Gr√°fico de barras agrupadas:** Distribuci√≥n de latencias P50/P95/P99 actuales por endpoint, permite comparaci√≥n visual r√°pida
  - **Tarjetas de m√©tricas (Cards):** Conexiones WebSocket activas (n√∫mero), cache hit rate (porcentaje), tasa de error HTTP (porcentaje con color rojo si >1%), operaciones offline pendientes (badge naranja)
  - **Tabla ordenable:** Top 10 endpoints m√°s lentos en √∫ltima hora con columnas: endpoint, P95, request count, error rate, bot√≥n "Ver detalle"
  - **Indicadores de salud (Health badges):** Verde si P95 <500ms, Amarillo si 500-1000ms, Rojo si >1000ms junto a cada m√©trica
- **Actualizaci√≥n:** Auto-refresh cada 10 segundos mediante polling a GET /api/metrics/current que retorna snapshot m√°s reciente
- **Interactividad:** Clic en punto de gr√°fico muestra tooltip con valor exacto, clic en endpoint de tabla navega a vista detallada con queries SQL sugeridas para optimizaci√≥n

#### 5.5. Alert Service
- **Ubicaci√≥n:** Backend, `server/services/alertService.js`
- **Responsabilidad:** Evaluar m√©tricas contra umbrales SLO definidos y enviar alertas a canales configurados
- **Canales de alerta configurables:**
  - **Console logs:** Siempre habilitado, logs con nivel ERROR en consola del servidor
  - **Webhook:** URL configurable via variable de entorno `ALERT_WEBHOOK_URL` para integraci√≥n con Slack, Discord o Microsoft Teams
  - **Email:** Lista de destinatarios en variable `ALERT_EMAILS` separados por coma, env√≠o via SMTP configurado
  - **WebSocket broadcast:** Emitir evento `system:alert` a room `admin-users` para notificaci√≥n en tiempo real en dashboard
- **Evaluaci√≥n peri√≥dica:** Ejecutada autom√°ticamente cada 60 segundos despu√©s de que Metrics Aggregator actualiza m√©tricas
- **Reglas de alerta implementadas con umbrales:**
  1. Si P95 latencia b√∫squeda productos >500ms en 3 ventanas consecutivas (3 minutos): Alerta nivel WARNING
  2. Si P95 latencia registro ventas >1000ms en 3 ventanas consecutivas: Alerta nivel WARNING
  3. Si P99 de cualquier endpoint >2000ms en una sola ventana: Alerta nivel CRITICAL inmediata
  4. Si tasa de error >1% en ventana deslizante de 5 minutos: Alerta nivel CRITICAL
  5. Si conexiones WebSocket activas >40 (80% de capacidad m√°xima 50): Alerta nivel WARNING preventiva
  6. Si cache hit rate <60% durante 10 minutos consecutivos: Alerta nivel INFO sugerencia de optimizaci√≥n
  7. Si operaciones offline pendientes >50 en promedio de √∫ltimos 5 minutos: Alerta nivel WARNING posible problema de sincronizaci√≥n
- **Formato de alerta:** JSON estructurado con campos: `level` (INFO/WARNING/CRITICAL), `timestamp`, `metric`, `currentValue`, `threshold`, `message` descriptivo, `actionSuggested` con recomendaci√≥n

---

### 6. Cat√°logo de Eventos de Dominio

**Responsabilidad:** Definir schemas tipados y versionados para todos los eventos emitidos por el sistema, garantizando contrato estable entre emisores y consumidores.

**Eventos instanciados con schemas:**

#### 6.1. stockUpdate
- **Emisor:** Inventory Service al actualizar stock tras venta, compra o ajuste manual
- **Payload JSON Schema:**
  ```
  {
    productId: number (required),
    productName: string (required),
    oldStock: number (required),
    newStock: number (required),
    action: string enum ["sale", "purchase", "adjustment", "return"] (required),
    userId: number (required),
    userName: string (required),
    timestamp: string ISO 8601 (required)
  }
  ```
- **Rooms de destino:** `pos-users`, `inventory-users`, `reports-users`
- **Frecuencia esperada:** Alta, 1-10 eventos por minuto en horario comercial

#### 6.2. lowStockAlert
- **Emisor:** Inventory Service cuando stock cae bajo umbral m√≠nimo configurado por producto
- **Payload JSON Schema:**
  ```
  {
    productId: number (required),
    productName: string (required),
    currentStock: number (required),
    minStock: number (required),
    category: string (required),
    urgency: string enum ["low", "medium", "high"] (required),
    timestamp: string ISO 8601 (required)
  }
  ```
- **Rooms de destino:** `inventory-users`, `purchases-users`, `admin-users`
- **Frecuencia esperada:** Baja, 0-5 eventos por d√≠a
- **L√≥gica de urgency:** `high` si stock <= 25% de m√≠nimo, `medium` si stock <= 50% de m√≠nimo, `low` si stock entre 50-100% de m√≠nimo

#### 6.3. saleCompleted
- **Emisor:** POS Service al confirmar registro exitoso de venta en BD
- **Payload JSON Schema:**
  ```
  {
    saleId: number (required),
    total: number decimal (required),
    itemCount: number (required),
    paymentMethod: string enum ["cash", "card", "mixed"] (required),
    cashierId: number (required),
    cashierName: string (required),
    timestamp: string ISO 8601 (required)
  }
  ```
- **Rooms de destino:** `reports-users`, `admin-users`, `inventory-users` (para trigger de stock update)
- **Frecuencia esperada:** Media, 5-50 eventos por hora seg√∫n tr√°fico de tienda

#### 6.4. productCreated
- **Emisor:** Inventory Service al crear producto nuevo en cat√°logo
- **Payload JSON Schema:**
  ```
  {
    productId: number (required),
    productName: string (required),
    category: string (required),
    price: number decimal (required),
    initialStock: number (required),
    createdBy: number userId (required),
    timestamp: string ISO 8601 (required)
  }
  ```
- **Rooms de destino:** `pos-users`, `inventory-users`, `admin-users`
- **Frecuencia esperada:** Baja, 0-10 eventos por d√≠a

#### 6.5. productDeleted
- **Emisor:** Inventory Service al eliminar o desactivar producto del cat√°logo
- **Payload JSON Schema:**
  ```
  {
    productId: number (required),
    productName: string (required),
    reason: string (optional),
    deletedBy: number userId (required),
    timestamp: string ISO 8601 (required)
  }
  ```
- **Rooms de destino:** `pos-users`, `inventory-users`, `admin-users`
- **Frecuencia esperada:** Muy baja, 0-2 eventos por semana

#### 6.6. customerCreated
- **Emisor:** CRM Service al registrar cliente nuevo en sistema
- **Payload JSON Schema:**
  ```
  {
    customerId: number (required),
    customerName: string (required),
    email: string (optional),
    phone: string (optional),
    loyaltyPoints: number default 0 (required),
    timestamp: string ISO 8601 (required)
  }
  ```
- **Rooms de destino:** `pos-users`, `admin-users`
- **Frecuencia esperada:** Baja, 2-10 eventos por d√≠a

---

[‚¨ÖÔ∏è Anterior](../9.4.3/9.4.3.md) | [üè† Home](../../../README.md) | [Siguiente ‚û°Ô∏è](../9.4.5/9.4.5.md)